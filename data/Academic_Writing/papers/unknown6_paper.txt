One of the primary tasks of natural language processing is morphological disambiguation. Morphological tags constitute the main tool of search in linguistic corpora, therefore assigning correct tags to words is extremely important. Morphological disambiguation can be performed manually, but it takes unreasonable amount of time and efforts. Moreover, the efficiency of manual disambiguation decreases with the growth of the corpus. Attempts to increase the pace and quality of disambiguation result in algorithms for automatic ambiguity resolution.
The Corpus of Modern Yiddish (CMY) is one of the corpora that need such an algorithm. The corpus is rather small: its volume is about 4 million tokens, however 1/2 of all words have lexical or morphological ambiguity. The present level of homonymy in the CMY impedes convenient and sufficient use of the corpus. Automatic disambiguation program would significantly contribute to the development of the Corpus of Yiddish and facilitate corpus-related research. As far as the author is aware, there has been no automatic ambiguity resolution software particularly for Yiddish so far.
The aim of this work is to develop a program for morphological disambiguation of the Yiddish language. This paper presents a review of the algorithms that can be applied to the disambiguation task, analyzes the output of each algorithm, suggests the best combination of these methods for applying to Yiddish  and shows the results of their work.
The existing methods of disambiguation are divided into two families: deterministic and statistic, i.e.~methods based on manually predefined rules and on automatically extracted data respectively. The present program combines methods from both these families.  First of all some ambiguities are solved by the  interactive disambiguation program that involves a user with knowledge of Yiddish. The approaches that I tested afterwards include Brill and Viterbi algorithms, and a bigram language model. The ultimate program is written in the Python programming language.
The best result shown by the program is 74.6. Section 2 of the paper introduces the markup of the Corpus of Modern Yiddish, its peculiarities and types of homonymy. Section 3 elaborates on each of the methods that I combine in the final program, describes the algorithms and their realization in Python. Section 4 presents the results: assessment of each algorithm and the efficiency of the ultimate program. Section 5 summarizes all the accomplished work and suggests plans for improvement.
Before I start applying algorithms, it is necessary to describe the structure of input files, the contexts of homonymy and to outline the main problems. I will start with  the input -- the corpus of Yiddish texts.
The Corpus of Modern Yiddish is a joint project of the Russian Academy of Sciences and the University of Regensburg, which started in 2007. The corpus comprises mainly publicistic texts, fiction is represented to a much lesser degree. For now the volume of the CMY is about 4 million tokens.
The CMY annotated texts are stored as XML files. The structure of the XML is the following: sentences are enclosed in tags texttt, each word is given inside the tags texttt, each morphological interpretation -- inside texttt. The  texttt tag has four attributes: lemma (texttt), morphological characteristics (texttt), translation into English (texttt) and transliteration of the word in the YIVO systemfootnote} (texttt). The word itself is written after the last  texttt tag. Punctuation follows the closing tag  texttt. Figure ref shows an example of an input file.
Let us pay attention to the peculiarities of annotation of some word classes.
A noun in Yiddish has 4 cases (nominative, genitive, dative, accusative), but the case forms look identical for most nouns. For this reason, almost all nouns are supplied with several analyses. Example  shows the three analyses that are always assigned to the noun ``literature''.
Even if I tried to resolve this ambiguity, a lot of ambiguous nouns would not be processed. Then if a user of the corpus inputs a query `N,f,sg, dat', he/she would receive some non-ambiguous dative nouns and a lot of homonymous nouns in other cases. This is rather inconsistent and extremely inconvenient in terms of search. Since complete resolution for all nouns is impossible, my program skips these multiple analyses. For this reason I have preprocessed the corpus and temporarily substituted all triple noun tags (Figure ref) for a simple single tag (Figure ref). 
Further, the existing annotation of the corpus is also rather inconsistent, as shown in : a tag of a plural noun can convey the information about its gender or not convey it, a Hebrew loan word may have the information about its gender, number and case   or it can have no exact information at all .
Verbs with separable prefixes (for example, ‘go out’ -- [aroysgeyn]  are supplied with at least two tags: a tag for the prefix which is analyzed as an adverb, and a  tag for the verb itself. It is also possible that a preposition is inserted between the prefix and the root (see Figure ref).
 Verbs can merge with pronouns into one word. They are supplied with at least two tags: a  tag for the pronoun and a  tag for the verb itself .
In the dative case prepositions are merged with the definite articles of masculine and neuter genders as in . Such merges are also supplied with at least two tags: a  tag for the preposition and a tag for the article which is analyzed as a pronoun-adjective (see Figure ref).
There are two other special cases: words with empty tags and words with no morphological analysis. Words with empty tags were not recognized by the parser . Some tokens were recognized as non-lexical elements, such as numbers, single letters and also words with non-standard orthography. These elements have no morphological interpretation  .
I am going to ignore some problems of the corpus. I do not try to deal with:
- triple noun cases (substitute them with singletons);
- empty tags (skip them);
- inconsistent tags (simply keep them in mind).
I try to resolve all the residual ambiguity paying special attention to the merges of prepositions with pronouns (PRON+PREP), verbs with pronouns (V+PRON), verbes with separable prefixes (V+ADV).  I treat these merges as one tag. In some algorithms I ignore the nonvarying part and only deal with the ambiguous one. For example, verbs with prefixes often behave as verbs without prefixes, so it is easier to delete the prefix, resolve the verb ambiguity and put the prefix back. In other algorithms (where only pos-tags are considered), it is more convenient to treat these merges as special tags, so that verbs with separable prefixes (V+ADV) have different POS-tags from usual verbs (V).
In this Section I will try to identify the enemy: what types of ambiguity I am struggling with and how I can estimate the level of ambiguity. Let us now enumerate the characteristics of the ambiguity in the corpus. I use the following notation:
--  the number of tokens;
 -- the number of morphological analyses;
 -- the number of ambiguous words;
 -- the number of non-ambiguous words;
 -- the number of words that had some tags deleted;
 -- the number of words that have no correct tags among the available variants.
To perform the assessment of the ambiguity the following three measures can be employed:
- Ambiguity rate. This value is equal to the number of morphological analyses divided by the number of words. In the ideal case, when all ambiguity is resolved, this value is equal to 1.
- The portion of ambiguous words. This value is equal to the number of ambiguous words divided by the number of words. In the ideal case, when all ambiguity is resolved, this value is equal to 0.
- The portion of non-ambiguous words. This value is equal to the number of non-ambiguous words divided by the number of words. In the ideal case, when all ambiguity is resolved, this value is equal to 1.
- Accuracy. This is equal to 1 minus the portion of words incorrectly tagged by the program. The number of incorrectly tagged words  is the number of words in the test sample which have the incorrect lemma and morphological analysis divided by the number of words in the sample that had some tags deleted by the algorithm. The number of incorrect tags is calculated by comparing with a sample of test sentences. I randomly chose 50 sentences (about 1000 words) from the corpus and manually disambiguated them. Then I counted how many words in the original sentences do not have the  tags that are present in the manually annotated sentences.
I will use these same measures to assess the efficiency of each  algorithm later.
Now I will provide the evaluation of these parameters for the CMYfootnote before applying the program.  is not given as it is irrelevant for the initial corpus.
The percentage of ambiguous words with full tags.
Each word in the corpus is supplied with a list of possible morphological interpretations. A morphological interpretation is a pair of an alleged lemma and possible gram tags (case, gender, number, etc.) corresponding to that lemma. My unachievable goal is to map each word to its correct tag. I say unachievable because of the nouns with triplet tags, compound tags in verbs with prefixes and articles with prepositions. For example, the ambiguity rate in the 50 manually disambiguated sentences is 1.15.
I extracted and counted all words that have homonymous tags to provide other numerical data characterizing the ambiguity. The corpus has 729 types of different combinations of tags in ambiguous words  and about 24000 different words that have homonimy. Observe that the corpus has about 2 million ambiguous words in total, and only 24 thousand different ambiguous words. According to Zipf's Law and these numbers, it is logical to assume that resolving some small amount of  the most frequent homonimy types should significantly lessen the amount of ambiguity.
The existing methods of disambiguation are divided into two families: deterministic and stochastic, i.e. methods based on manually predefined rules and on automatically extracted data respectively. Methods of these two families can be combined. 
These methods imply that some lists of rules are compiled manually in a specifically designed universal format. Since the rules are predefined by the researcher, this method is very well controlled.
Statistic methods are connected with machine learning. Machine learning implies having a huge manually disambiguated corpus, which can be used for training the algorithm. These algorithms are less controlled, since the execution of the code is not seen and is not transparent. The most widely known method of this family is a Hidden Markov Model.
In the following sections I briefly describe each method and comment on its realization in Python.
Technically, disambiguation in the corpus is the task of excluding wrong tags. The problem is: how do we teach a machine to decide which tags are wrong? One possible decision is to count the probabilities of tags in their environment and to keep only the tags with the maximum probability. This is a rough description of an N-gram model. For a start, I would like to create an bigram model for our corpus and disambiguate with it. 
Training a good bigram model requires a manually annotated corpus which I do not have. For this reason, I decide to automatically extract non-ambiguous parts of the corpus and treat it as an etalon.  Non-ambiguous bigrams are those both words of which have no ambiguity. About 1.7 million of tokens in the CMY have no ambiguity, which comprise 41In the Python programming language, the bigram model is realized as a dictionary where each key is a morphological tag and the corresponding value is an array of tuples. Each tuple contains a) a tag that may follow the key and b) the probability of a bigram (key + such tag).
Then  I write a script that  runs through the corpus and looks for ambiguous words. For each such word the script checks whether the previous word is not ambiguous, and if so the script would consult the bigram model, choose the most probable tag out of the given and delete all the redundant analyses from the current word interpretation.
Let us illustrate how the model works. For example, the model contains a frequent non-ambiguous bigram texttt followed by texttt. When the script meets the tag texttt followed by an ambiguous word with tags texttt, texttt and texttt, it would keep texttt and delete the others.
A serious disadvantage of this method is that here are bigrams which are never processed, because they are always ambiguous. They are not represented in the model, and hence, the script just skips them.
The script collected 1002631 bigrams, made 594761 changes.
One of the methods of disambiguation is described in [Brill 1995], which is based on Transformation-Based Error-Driven Learning suggested by Brill.
The original algorithm has three parts: the initial-state annotator, the space of possible transformations, the function of assessment.
Raw texts are processed with the initial-state annotator, which assigns a tag to each word. Then the transformations are applied to the corpus and  the assessment function is evaluated for each transformation. For each state of the corpus the most successful transformation is chosen which is then added to the ordered list. The learning ends when it is impossible to find any successful transformation. New texts then are processed by the initial-state annotator and then are run through the transformations in the ordered list. 
For the tagging task, the initial state annotator usually assigns the most probable tag to each word. The set of possible transformations is defined in the templates. Then the algorithm fills the templates with  the values of some precomposed set of tags or words. The function of asessment usually compares the transformed corpus with a manually disambiguated training corpus and returns the degree of similarity. The transformations driven from such process have the following form:  ``Change tag A to tag B if the previous tag/word is C''.
If no manually annotated corpus is available, it is still possible to use Brill’s algorithm. The initial state annotator assigns to each word  all its possible tags, and the transformations are meant to erase the wrong analyses. Since I already have the corpus where each word has all its possible tags, I skip the initial-state annotator.
In the next step I define the templates for transformations. I take into account 1 word and 1 tag to the right and to the left, that is 4 templates.
The last step is to define the function of assessment. For this task I use the extracted non-ambiguous fragment of the corpus. The transformation ``Change tag A to tag B if the previous tag is C''  is assessed  according to the formula.
Out of all possible M such tag P is chosen that maximizes this function. Then for the assessment of each transformation I evaluate the expression
I use Brill algorithm for part of speech (POS) disambiguation only, i.e. to resolve the cases when more then one part of speech is present in the analyses of the word.
At some point the growth of the number of rules does not improve disambiguation, because the algorithm can generate rules that cover very rare words. So I decided to limit the number of rules to 500. Figure ref shows several rules generated by my program for Yiddish.
The tag set for Brill algorithm was generated from the morphological analyses given in the corpus. My tag set includes 22 tags which are given in Table ref together with their meaning.
However, the algorithm sometimes keeps wrong parts of speech, which can be explained by two reasons:
1. weakness of the algorithm - it does not properly model the language,
2. weakness of the initial annotation - parser did not offer the correct variant.
The numerical output is the following.
Another algorithm used for POS-tagging is the Viterbi algorithm. Given a Hidden Markov Model (hereafter, HMM) and a sequence of observations, the Viterbi algorithm discovers the best hidden sequence of states.  In our case, a sequence of observations is a sequence of words, i.e.~a sentence, and a hidden sequence of states is a sequence of tags corresponding to each word in that sentence.  An HMM is specified with the following components:
- a set of N states (=tags),
- a transition probability matrix (=probability of a tag following another tag),
- possible observations (=words),
- emission probabilities (=probability of a word being generated from a tag),
- a special start state and a final state.
An HMM for the algorithm is based on the same non-ambiguous part of the corpus that was used for the bigram model. Thus I created two HMMs: the states of the first model are just the 22 POS-tags that were used in the Brill algorithm, the states of the second model are full tags (part of speech plus other grams).
 The transition probability matrix has zero probabilities for bigrams which are possible but were not encountered in the extracted fragment, since the number of bigrams (=transitions)  in the fragment is rather low. To avoid zero probabilities I use a simple smoothing strategy -- add-one smoothing.
However, whatever the efforts, the algorithm shows very poor results. It almost never guesses the tags that were offered by the parser, but assignes completely different parts of speech. The script that applies the results of the Viterbi decoding to the corpus changes tags only in case that Viterbi and parser coincide in one of them. Unfortunately, somehow this never happens. Probably, training an HMM on the bigrams is not efficient enough. I should try to learn an HMM on a training corpus. Another possible reason is that a better smoothing strategy is needed. Add-one smoothing is still one of a very primitive kind.
Manual disambiguation is usually more accurate, but it is a very tedious process. Imagine that a corpus has 3000 instances of a trigram 1.~texttt, 2.~texttt or texttt or texttt, and 3.~texttt, where the second word is ambiguous and has three possible tags. The correct tag is obvious, but a human would have to disambiguate this one simple trigram 3000 times. It would be more convenient to resolve such morphological ambiguity just once and then automatically apply the result to all corresponding cases. Such disambiguation process would involve a linguist and an automatic text processor. An interactive program for partial automatic disambiguation was developed by Elizaveta Kuzmenko for the Corpus of Modern Greek.
The program collects ambiguous unigrams, bigrams and trigrams in the corpus and sorts them by frequency. Then the program shows one of the collected items to the user and offers to choose which variant is correct. 
The user can mark the correct answer or delete the wrong variants. If the user is not sure how to resolve ambiguities, they can be skipped. The accuracy of this method depends on the knowledge of language. Assuming that the linguist knows the language, this algorithm is very accurate.
 However, the program does not take into account some specificities of the YNC. For example, YNC has words with empty tags and empty gr, and merge cases.
I applied the program to the CMY and applied it to the Yiddish texts. Figure shows an example of the program's query. 
With the interactive method I manually resolved some of the most frequent ambiguities in the CMY. The program progress depends on the disambiguation rate of the user, but it is still faster than completely manual work. The numerical output is the following.
The results of applying each method to the original corpus are shown in comparison in Table ref, the best result in each row is highlighted. As can be seen from the table, the most accurate result is shown by the interactive program, and the method with the most broad coverage is the bigram language model. Low accuracy of the Brill algorithm can be explained by the fact that I used only POS-tags, thus reducing the amount of necessary information. 
I decided to apply all the methods one after another. It is logical that the most accurate methods should be applied first. The result is shown in Table ref and in Figure ref.
Various approaches to  automatic ambiguity resolution of the Yiddish language were tested and the best combination of methods was revealed. The suggested sequence of methods is the following:  interactive disambiguation, bigram model, Brill algorithm. With this three methods I disambiguated 74.6  All the source codes except for the interactive disambiguation program are available at url.
A lot of work still needs  to be done in the future. Here is the list of what I plan to realize:
-  Rerun Viterbi with better smoothing. I suppose that the poor result of the Viterbi script is due to unsophisticated smoothing strategy. Probably, a better smoothing would show better performance.
-  Speed up the Brill algorithm. For now the script for the Brill algorithm is rather slow which is very inconvenient for processing big amounts of data.
-  Find a bigger manually annotated corpus and train the algorithms on it. Manually annotated corpus would be a better training corpus for our algorithms than the extracted non-ambiguous bigrams.
-  Deal with some of the problems that were ignored: inconsistent tags and nouns.
I hypothesize that the above actions will improve my current result. The output of the work will be available on the Internet. The improved corpus will significanly facilitate corpus-related research and contribute to the development of the Corpus of Yiddish.
