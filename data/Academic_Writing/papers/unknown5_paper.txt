1. 	Introduction
Corpora in linguistics are large collections of texts enhanced with special markup. They allow linguists to search the texts by various parameters in order to discover phenomena and patterns in the natural language. Corpus studies are the state of the art method in most areas of linguistics. In the recent years, corpora started to make their way into other humanities, such as history, sociology or psychology.
Musicology is another field that could benefit from corpora, but has not yet done so. In fact, most online resources that position themselves as music corpora are comprised of sheet music collections without annotation or search capabilities. As a result, a musicologist wishing to conduct a study must gather their own corpus. They may then process it with optical recognition software (Audiveris, OpenOMR) and extract data with a programming language of their choice. The alternative is to look through the scores and find the features of interest by hand.
Considering the situation, we propose to develop a corpus for computer-aided musicology. Such a corpus would allow the researchers to find melodies and patterns in music just as linguists find language patterns. We devise a database structure underlying the corpus, that is, find the best representation for music scores and implement the search logic. After this, we develop the corpus interface that will allow searching the database online without extra software on user’s side. In addition, this interface gives access to in-depth analysis of individual pieces, performed automatically by Python modules in the backend. At this stage, we did not address the issue of content, but focused on developing the framework.
So far there have been few attempts to create open music corpora. To the best of our knowledge, most progress has been made in the area of music retrieval. Various music retrieval systems exist, with different methodologies and target users (Typke et al. 2005). These systems, however, are mainly developed as search engines, and lack additional functionality. We thus assume that no solution analogous to ours is openly available at present.
This paper is designed as follows. In the first section we analyze the methodology behind corpus studies in musicology and provide an overview of existing tools. We then justify the development of our corpus and set design guidelines and goals. In the next section we describe the corpus structure: how music scores are represented and searched. We also comment on the interface and what capabilities of in-depth analysis are available through it. Finally, we discuss the results and make an outline of future work.
2. 	Corpus methods in musicology
In this section we will explain why corpora for computer-aided musicology should be developed. Corpus studies are employed in various fields from genetics to sociology. The reason for this is that using large collections of data opens a different approach to research. Through corpus studies one may obtain a quantitative representation of facts, and thus discover new patterns in data, which are otherwise hard to see.
Before the age of computers, musicology had made use of thematic catalogues. These catalogues resembled inverted indices in that they contained fragments of music (either the beginning or recognizable themes) and a list of music scores where these fragments can be found. Such catalogues varied in amount of information they provided – from complete extracts to select features like pitch and rhythm (Brook 1980). 
As computers were introduced, researchers started looking for new ways to index and search music. The resource called Répetoire International des Sources Musicales  develops the thematic catalogue idea in a new digital dimension. Another large area of research is feature extraction and analysis. Numerous solutions have been developed (e.g. iAnalyse Studio , Wavepad ). They can be used to process a wide variety of data, but they require a corpus of documents to be gathered beforehand.
This approach – gathering a collection of documents by metadata and then processing it with software – is the method of choice in recent musicology studies. For example, a corpus study of rock music (De Clerq, Temperley 2011) took the Rolling Stone song list  as a base. As a result, such studies are limited to a pre-defined scope of genres, time periods and authors. This is a valid approach to studying music, but it requires a sufficient amount of time and effort for data collection. We consider it possible to conduct a large proportion of such studies on a general corpus or its subcorpus with standard search and analysis capabilities. Therefore, developing such a corpus would save preparation time for studies in musicology, and possibly increase their number and quality. In addition, an open corpus could facilitate a new type of pattern-based research, where scholars take a musical feature or a pattern as a base and determine its scope in music. This type of research could reveal links between different ages and genres, which are otherwise difficult to predict.
When developing the corpus, we kept several guidelines in mind. Firstly, the corpus should be easily accessible and system-agnostic. For this reason, we chose to make a web version, which only requires a modern web browser and internet connection. Secondly, adding new data to corpus should be easy. This is why we developed an automatic solution which extracts features from text-based music files and updates the database. Finally, a corpus should be more than a search engine, and for this reason we provide various infographics generated automatically for each piece of music (see part 3.3).
3. 	The corpus structure
In this section we will describe the structure of our corpus: how music scores are represented in the backend and how the database is constructed. We will also touch on the interface and the features it provides.
3.1	Music representation in corpus
Our corpus uses text-based representation of music scores. To make music searchable by melody and rhythm, we extract data from raw files when they are added to corpus and record it as strings of text. For the initial files, multiple formats are supported, e.g. MusicXML, MIDI, ABC and others. 
In order to search music scores, we must define search terms, or words. Music cannot be readily divided into meaningful segments, since music semantics is difficult to determine. We decided to adopt an approach from (Downie 1999), namely, to mechanically divide melodies into n-grams. In this work it was proven that n-grams are sufficient to convey meaningful features in music. According to Downie, n-gram representation has its advantages over traditional methods. Approximate matching techniques (see e.g. Orio 2008) are “computationally expensive”, and digital thematic catalogues “leave out large amounts of music that may be of interest”. With n-grams, the whole music score is indexed, and thus it becomes possible to find any fragment of music in the database in a relatively short time. Several works have explored the n-gram approach, for example, to find discriminatory features in music (Yip, Kao 2000) and to adapt the approach to polyphony (Doraisamy 2004). N-grams are successfully used to determine music similarity, see e.g. Peachnote similarity browser (Viro 2011).
For the reasons listed above, we consider n-gram representation an optimal method for our corpus. To extract n-grams, we first parse the file containing text representation of music with a tool called Music21 . We then record all notes and rests from the score and leave out clefs, time signatures and other notation objects. Note that in the current version of corpus each part of a polyphonic piece is treated separately. When a piece is presented as a sequence of notes and rests, we convert it from exact pitches to interval notation, i.e., we record a) intervals between adjacent notes in semitones and b) durations of these intervals in quarter lengths. The interval between a note and a rest is taken for 50 semitones, because such an interval is unlikely to occur naturally. Intervals may be negative, if the following pitch is lower than the current pitch. Thus, we obtain two strings of numbers that represent a melody.
After conversion, the two strings are separated into subsequences of length 6 overlapping by one element. Trigrams (we use n = 3 for n-grams), in their turn, are extracted from each subsequence with “one-sliding technique” (see fig. 2). Sequences and trigrams are then used to construct a search index as described in the section below.
3.2	Database structure
In this section we will describe the database structure underlying the corpus. The database consists of two logical parts. The first part contains information about music scores indexed in the corpus: their title, composer’s name, date of creation and other metadata. It also lists the filenames to access scores in the file system. The second part is used for searching the scores: it contains subsequences and trigrams extracted from music as described in the section above.
The trigram-subsequence-score relationship is organized as an inverted index. Inverted index is a structure that maps search terms, or words, to the documents where these words can be found. Inverted indices are widely used in text search and document retrieval because of their speed. Although query processing in such indices is very fast, building an inverted index requires a sufficient amount of time and computer memory.
To reduce database size and query processing time we decided to build a two-level index. This structure introduced in (Kim et al. 2005) offers significant performance perks compared to a simple inverted index. The back-end level (fig. 3.2) is occupied by subsequences of length 6. Each 6-sequence contains two separate layers of pitch and rhythm information. The combination of these two parameters is considered unique. Each record contains a list of documents and exact positions where a sequence can be found. Trigrams occupy the front-end level (fig. 3.1), and each record contains a list of sequences where a trigram can be found. 
Subsequence length of 6 is optimal according to (Kim et al. 2005). 6-element sequences offer the best index size ratio, i.e., the two-level index built on 6-sequences occupies up to 2.2 times less space than a simple inverted index on a database over 100 megabytes. In (Kim et al. 2005), trigrams are used for the front-end index without explicit justification, but we find them suitable for our purposes.
3.2.1	Search algorithm
In order to retrieve documents matching the user’s query, we employ the following algorithm. First, all trigrams are extracted from the query. If the query only contains one layer (i.e. pitch or rhythm), we proceed with it; if it has both, we first perform search by pitch sequence, which is expected to match fewer documents than rhythm sequence, and then refine search results to match rhythm information. 
After trigrams have been extracted from query, we perform index search to make a list of subsequences. Note that if query length is less than three, we search for trigrams that contain the query; otherwise, we search for exact match in the list of trigrams. On this stage we obtain a list of subsequences that may constitute a part of a query. For each sequence, we check if it “covers” the query. The term is introduced in (Kim et al. 2005) and is interpreted as follows: a sequence covers the query if a) it contains the query, b) it is a part of a query, c) its prefix matches the query suffix or d) its suffix matches the query prefix. 
With the sequences that passed the cover check, we proceed to the second level of the index. We retrieve all document lists corresponding to sequences, and then invert these lists to a simple index, where each document has a posting of relevant sequences found in it. Only the sequences that possibly satisfy the query make it into these lists. For each document and its posting list, we try to expand the sequences: merge the strings which are adjacent, according to position information stored in the database. We then check if the merged sequence contains the query. If it does, the corresponding document is returned in search results.
3.3	Interface
One of the goals of this project was to make the corpus available to the wide public. We decided that the best implementation for a public resource would be a web-based application. To develop the corpus, we used SQLite  for the backend (database), Django  1.5 for logic, and Twitter Bootstrap  for frontend (interface). The corpus operates in a browser and does not require additional software.
Corpus search is performed by manually entering interval and/or rhythm information in the specified format. We realize that lack of intuitive input methods reduces the corpus usability, and thus we make better input support our top priority for further development. After search is performed, the user receives a list of titles with composer and year of composition. In addition to search capabilities, we developed an information page about each document in the database. When the user receives the documents matching their query, they may then browse them individually. For open music, the whole score is displayed. For all the files, we provide a selection of quick analyses performed by Music21, which helps to identify features of interest at a glance. The results of these analyses are displayed as graphs. At this moment we provide the following graphs:
-	A pitch class histogram which displays how many times each pitch has been used in the piece;
-	A movement graph (with polyphony support) which shows pitch changes over time (fig. 5);
-	A key diagram which displays key changes determined with Krumhansl-Schmuckler (Krumhansl 1990) analysis;
-	A dynamics plot which shows dynamics changes over time.
We plan to introduce additional analyses for quick view based on user feedback.
4. 	Results and future work
As a result of this work, we developed a framework for monophonic melody search by pitch and rhythm. The system returns a list of relevant documents according to the user’s query and displays a fragment of each document where the query can be found. It also offers additional information about individual documents, such as year and country of composition, genre, graphs of dominant pitches, dynamics changes, and other data. The system does not require installation and works in any modern browser.
An important limitation of this work is that we did not address the issue of corpus content. Some music in text format is openly available and can be indexed in a corpus, but copyright can significantly limit the content diversity. For several types of studies, it is important that a corpus is balanced, that is, contains pieces of different genres and ages in certain proportions. As a workaround, we may display small parts of scores directly relevant to the query, without giving access to whole music pieces. It is possible that metadata and the analysis we provide also falls into the category of freely distributable information. To compensate for content limitations, we developed a program that allows to expand the corpus with minimal effort on the user’s side. This solution allows anyone to upload their own music files in several formats, which will then be indexed and made searchable. We plan to integrate this solution in the corpus interface in the nearest future, so that the corpus could be filled with free content with a crowdsourcing effort (a similar approach is used in Musipedia ).
This project is a work in progress, and it needs further development to compete with other available solutions. We plan to diversify input methods to include piano roll and staff editors, virtual keyboard and query by humming. The latter will require an adaptation of search mechanics to facilitate approximate matches. This change to the two-layer database structure can be implemented as described in (Kim et al. 2007). As to the more distant development, we believe that polyphonic search is the next logical step. One way to enable it is by providing multiple search fields and the means to define relationships between them, as in e.g. IMDI browser . True polyphonic search can also be developed, see e.g. (Doriasamy 2004)
